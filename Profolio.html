<!DOCTYPE html>
<html>
<head>

<!-- your webpage info goes here -->

    <title>Zhihan's Profolio</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="css/home.css" type="text/css" />
	 <link href="css/style.css" rel="stylesheet">
</head>
<body>

<!-- Nav section -->

	<div id="page">
		<div id="logo">
			<h1><a href="" id="logoLink">LOGO</a></h1>
		</div>
		<div id="nav">
			<ul>
				<li><a href="About.html">Who</a></li>
				<li><a href="Project.html">Projects</a></li>
				<li><a href="Contact.html">Contact</a></li>
			</ul>	
		</div>
		<div id="content">
            <img class="p1" src="image/projects/zh.png" alt="My second project">
			<h2>WHO I AM</h2>
			<p>
				I am an enthusiast in user interface design, interactive media system design. I love exploring the field of user experience design and i think design is a way of thinking and the ability to understand people’s everyday experiences. I pay close attention to the development of the high-new technology such as the immersive interactive applications based on the advanced computing technology and body interface interaction. With a few years of experience in the intersection of technology and the creative events, I have the ability to overcome the challenge from sound editing to interactive user interface design.
			</p>
			<a class="button_about" href="#">About Me</a>
		</div>
        
        
        
        
         <!--Projects Section-->
        <section id="project">
         <div id="content">
            <h2> Project1 </h2>
            <img class="p1" src="image/projects/maxmsp.png" alt="My first project">
              <p>In this Project I designed 3 interaction forms to get interact in Max at the sametime. Firstly, I use the Arduino UNO to communicate with the Max. I use Arduino Water Level Sensor to trigger a sound according to the sensor get into to the water. By chatting with the Max. If the sensor touch the water, the sound will be play in the speaker. In Max, when the value less than the value 200, it will activate the switch but the audio playback mad. It continues to arrive from an active toogle signal. It activates the togedge. If the value exceed 200, the sounding will get block. Moreover, i overcome the problem in the Max to makesure user can use mouse or touch to draw the blank board to get interaction with the real-time cam on the computer. Different waveform sounds frequency will be activate and playing when user drawing on the board. Meanwhile, the object that the cam captured will distortion. If user press the “close”button on the interface, the image that camera captured will be static.Lastly, user also can click or touch the piano or just press the "button" shown on the interface to get more interactive sound playing effect. If user interact with the interface at the same time, it can create an interesting diegetic sound playing.
I really enjoy doing these project, it is so attractive. I have learned a lot about how to make interactive sound installation by using Max communicate with other devices.</p>
      
       </div>
        
     


        <div id="content">
            <h2> Project2 </h2>
              <img class="p1" src="image/projects/Processing_result.jpg" alt="My second project">
            <p>Humanity In-Dependence consists of a single screen projection of an image that
can change based off of audience interaction. The audience can interact with the
artwork by shining a flashlight at the light sensor located inside the grey box
container. Upon detecting the flashlight, the screen will switch back and forth between
that of a human face and a robotic face. The challenge I met was the projected image was initially a static image. I should make the image to be more dynamic prior to the prompt of the flashlight so that the artwork is less static when seen from a distance. To solve the problem, I re-programmed in the processing of the image. so that it would fade back and forth between the two images via a timer.The audience can continue manipulate the image for as long as they have the flashlight aimed at the light sensor or until they decide to leave. The project requires a person to input a light source in reality which will manipulate the digital space through a computer. I found that the primary visual feedback given by digital image manipulation requires both human and machine working together for a successful interaction to take place.</p>
              
           </div>
          
    
    

             
     </section>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
		<div id="footer">
			<p>
				Zhihan Wei <a href="" target="_blank">zhihan wei</a>
			</p>
		</div>
	</div>
</body>
</html>